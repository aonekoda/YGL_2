{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모형의 선택\n",
    "* 최적의 모형을 선택하기 위해 적당한 하이퍼파라미터의 설정이 중요하다.\n",
    "* 여러가지의 후보 모형에서 효율적으로 최선의 모형을 선택하는 기법을 다룬다.\n",
    "    * 완전탐색 기법 \n",
    "    * 랜덤탐색 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전탐색 기법\n",
    "사이킷런의 GridSearchCV를 사용한다. 하이퍼파라미터의 **모든 조합**으로 모형을 훈련하여 최적의 하이퍼파라미터를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 로지스틱 회귀 모델을 만듭니다.\n",
    "logistic = linear_model.LogisticRegression(solver='liblinear', max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터의 후보값을 설정한다.   \n",
    "penalty 방법과 규제 변수인 C에 적당한 후보값을 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페널티(penalty) 하이퍼파라미터 값의 후보를 만듭니다.\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# 규제 하이퍼파라미터 값의 후보 범위를 만듭니다.\n",
    "C = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# 하이퍼파라미터 후보 딕셔너리를 만듭니다.\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사이킷런의 그리드 서치 기능은 모든 조합에 대해 모형을 훈련한다.  \n",
    "* 최고의 성능을 내는 모형을 최종 모형으로 선택한다.  \n",
    "* K-fold cross validation기법을 사용한다.\n",
    "### GridSearchCV\n",
    "* verbose =0 이면 아무것도 출력하지 않고 1~3 값을 주면 자세한 내용이 출력된다.\n",
    "* n_jobs = -1 로 설정하면 모든 CPU 코어를 사용하여 병렬로 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드 서치 객체를 만듭니다.\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "# 그리드 서치를 수행합니다.\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모든 조합에 대해 모형을 훈련하므로 시간이 많이 소요될 수 있다.\n",
    "* 위 설정에서 패널티는 2개, C 규제변수의 값은 5개, fold 수는 5개  \n",
    "* 총 2x5x5 = 50개의 모형중 최선의 모형을 선택한다.\n",
    "* GridSearchCV가 완료되면 최선의 모형을 만드는 하이퍼파라미터를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 페널티: l1\n",
      "가장 좋은 C 값: 10\n"
     ]
    }
   ],
   "source": [
    "# 최선의 하이퍼파라미터를 확인합니다.\n",
    "print('가장 좋은 페널티:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('가장 좋은 C 값:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터를 적용한 모형의 성능을 확인한다.\n",
    "best_model.score(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤탐색 기법\n",
    "사이킷런의 RandomizedSearchCV을 사용한다. 완전탐색 기법보다는 최적 모형을 선택하는데 드는 계산 비용을 줄인다. 랜덤한 하이퍼파라미터의 조합으로 조사한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "from scipy.stats import uniform\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 로지스틱 회귀 모델을 만듭니다.\n",
    "logistic = linear_model.LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터의 후보값을 설정한다.  \n",
    "penalty 방법과 규제 변수인 C에 적당한 후보값을 설정한다.\n",
    "\n",
    "### RandomizedSearchCV\n",
    "RandomizedSearchCV에서 분포를 지정하면 이 분포에서 중복을 허용하지 않도록 하이퍼파라미터의 값을 랜덤하게 샘플링한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페널티 하이퍼파라미터 후보를 만듭니다. penalty hyperparameter values\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# 규제 하이퍼파라미터 값의 후보를 위한 분포를 만듭니다.\n",
    "C = uniform(loc=0, scale=100) # 0~100 사이의 균등분포에서 랜덤하게 샘플링한다.\n",
    "\n",
    "# 하이퍼파라미터 옵션을 만듭니다.\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# 랜덤 서치 객체를 만듭니다.\n",
    "randomizedsearch = RandomizedSearchCV(\n",
    "    logistic, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=0,\n",
    "    n_jobs=-1)\n",
    "\n",
    "# 랜덤 서치를 수행합니다.\n",
    "best_model = randomizedsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV에서와 마찬가지로 최적 모형의 하이퍼파라미터를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 페널티: l2\n",
      "가장 좋은 C 값: 93.25573593386588\n"
     ]
    }
   ],
   "source": [
    "# 최선의 하이퍼파라미터를 확인합니다.\n",
    "print('가장 좋은 페널티:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('가장 좋은 C 값:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터를 적용한 모형의 성능을 확인한다.\n",
    "best_model.score(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 학습 알고리즘에서 최선의 모델 선택하기\n",
    "\n",
    "다양한 학습 알고리즘과 각각의 하이퍼파라미터를 탐색하여 최선의 모형을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 랜덤 시드를 설정합니다.\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 파이프라인을 만듭니다.\n",
    "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀 모형과 랜덤포레스트 두 개의 학습 알고리즘을 학습 탐색에 포함 시킨다. \n",
    "딕셔너리를 사용하여 학습 알고리즘과 탐색하고자하는 하이퍼파라미터를 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후보 학습 알고리즘과 하이퍼파라미터로 딕셔너리를 만듭니다.\n",
    "search_space = [{\"classifier\": [LogisticRegression(solver='liblinear', max_iter=500)],\n",
    "                 \"classifier__penalty\": ['l1', 'l2'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)},\n",
    "                {\"classifier\": [RandomForestClassifier()],\n",
    "                 \"classifier__n_estimators\": [10, 100, 1000],\n",
    "                 \"classifier__max_features\": [1, 2, 3]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드 서치 객체를 만듭니다.\n",
    "gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
    "\n",
    "# 그리드 서치를 수행합니다.\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=7.742636826811269, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=500, multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최선의 모델을 확인합니다.\n",
    "best_model.best_estimator_.get_params()[\"classifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
